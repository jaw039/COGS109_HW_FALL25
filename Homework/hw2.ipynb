{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "79d39222",
   "metadata": {},
   "source": [
    "# Homework 2 - Linear Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2064271a",
   "metadata": {},
   "source": [
    "Jackie Wang"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5489c025",
   "metadata": {},
   "source": [
    "## PART A: Concepts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da3efebe",
   "metadata": {},
   "source": [
    "1. Model Setup\n",
    "\n",
    "    a.State the simple linear regression (SLR) setup (ISLP Eq. 3.1) and define each term in the equation.\n",
    "\n",
    "    yi​=β0​+β1​xi​+ϵi\n",
    "\n",
    "    yi is the response (output)\n",
    "\n",
    "    Xi is the predictor (input)\n",
    "\n",
    "    Bo is the intercept\n",
    "\n",
    "    B1 is the slope\n",
    "\n",
    "    e is the random error\n",
    "\n",
    "    b.List and briefly explain the basic assumptions of the SLR model.\n",
    "\n",
    "    - Linearlity: Assumption of SLR is that the relationship between the predictor x and the response y have a linaer relationship. \n",
    "    - Independ Erros: The error e are independent of each other / erros are uncorrelated\n",
    "    - Constant variance: the errors have the same variance across the values x\n",
    "    - the errors are normally distributed with mean 0\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25384c98",
   "metadata": {},
   "source": [
    "2. Model fitting. In your own words, explain how the coefficients of the SLR model are estimated (i.e., how we “fit” the model). \n",
    "\n",
    "Coefficients are estimating the best intercept and slope so that the resulting line are as close to our features/data points as possible. In SLR we would get this by minimizing the Residual Sum Of Squares (RSS) total squared differnce between the observed values and the predicted values/  y- yhat.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f923941a",
   "metadata": {},
   "source": [
    "3. Interpretation. In your own words…\n",
    "\n",
    "a. Explain the difference between the population regression line and the least squares line.\n",
    "\n",
    "The population line are from real data it represents the true relationship between X and Y in the entire data. It uses unknown parameters. \n",
    "\n",
    "Least Square Lines are estimates of the relationship based on the sample data we have it uses the estimated coefficeints parameters. \n",
    "\n",
    "b. Define the standard error and explain what it tells us about the estimated parameters.\n",
    "\n",
    "The standard errors tells us the how close our estimated parameters are to the true parameters. \n",
    "\n",
    "c. Define confidence intervals and explain what it tells us about the estimated parameters.\n",
    "\n",
    "Confidence intervals is a range of value that captures the true values of a population parameters with a certain level of confidence. It tell us how accurate our estimated parameters are.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b342fd0c",
   "metadata": {},
   "source": [
    "Applied example. Consider the SLR model: examScore0+1hoursStudied+\n",
    "\n",
    "a. State the null and alternative hypotheses being tested in this model.\n",
    "\n",
    "H0 null : Beta = 0 hour studied has no relationship with exam score\n",
    "HA alternative: Beta does not equal to 0 hours does have a relationship with exam score\n",
    "\n",
    "b. Interpret each coefficient: write one sentence for each coefficient explaining its meaning in context of the problem.\n",
    "\n",
    "Interept (3.4): When a student studies 0 hrs their exam score is 3.4 points\n",
    "HoursStudied (1.5): for each additonal studied the exam score is expected to increase by 1.5 points on avg.\n",
    "\n",
    "c. Are the coefficients statistically significant? Explain how you came to that conclusion.\n",
    "\n",
    "yes both p value are less than 0.001 which is smaller than 0.05 threshold. This mean that both coefficeints are statstically signifcant. \n",
    "\n",
    "d. Suppose the 95% confidence intervals (CIs) for 0=[1.8,5.0] and for 1=[1.1,1.9]. Write one sentence of interpretation for each CI in context.\n",
    "\n",
    "0=[1.8,5.0] we are 95% confident that true avg exam score for students who study 0 hrs lies between 1.8 ad 5.0 points. \n",
    "\n",
    "1=[1.1,1.9] we are 95% confident that each additonal hr studied increase the true avg exam score by 1.1 and 1.9 points.\n",
    "\n",
    "e. For your model, you compute RSE=5.2 and R2=0.62. Write one sentence for each metric that interprets it in the context of the problem.\n",
    "\n",
    "RSE = 5.2 that means the difference between actual score and predicted exam score is about 5.2 points.\n",
    "R^2 - 0.62 means that 62% of the variation in exam score can be determined by the number of hrs studied."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9H77UcsI5Yg2",
   "metadata": {
    "id": "9H77UcsI5Yg2"
   },
   "source": [
    "\n",
    "**Estimated completion time: 1.5 hours**\n",
    "\n",
    "**Workflow:**\n",
    "1) **EDA / exploratory checks** (scatterplots with LS lines)\n",
    "2) **Fit SLR** with `statsmodels.api.OLS` (manual `add_constant`); interpret\n",
    "3) **Diagnose SLR** (residuals vs. fitted)\n",
    "4) **Fit MLR** with **backward selection** using `statsmodels.api.OLS` (numeric predictors only)\n",
    "5) **Predict with `sklearn.linear_model.LinearRegression`** and compute **RMSE**\n",
    "6) **Compare SLR vs MLR** on the same split\n",
    "\n",
    "> **Comments marked **# YOUR CODE HERE** must be completed for the code to run\n",
    "\n",
    "> **Please also make sure you are pasting your plots and answering any questions in the document in the **main homework document**, not in this notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "z1233gc_5Yg3",
   "metadata": {
    "id": "z1233gc_5Yg3"
   },
   "source": [
    "## Part 0 — Setup\n",
    "### Importing packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "H6PtrY0N5Yg3",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 28763,
     "status": "ok",
     "timestamp": 1759726944502,
     "user": {
      "displayName": "Lucy Lai",
      "userId": "13106468595873100443"
     },
     "user_tz": 420
    },
    "id": "H6PtrY0N5Yg3",
    "outputId": "cc5754eb-6bd8-446c-fcc6-7971a51c3918"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.6/3.6 MB\u001b[0m \u001b[31m22.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m349.3/349.3 kB\u001b[0m \u001b[31m9.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m80.2/80.2 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m832.4/832.4 kB\u001b[0m \u001b[31m18.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m983.2/983.2 kB\u001b[0m \u001b[31m21.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m117.3/117.3 kB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Building wheel for autograd-gamma (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
     ]
    }
   ],
   "source": [
    "# If running locally and packages are missing, uncomment:\n",
    "!pip install -q ISLP statsmodels scikit-learn pandas numpy matplotlib\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import statsmodels.api as sm\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "pd.set_option(\"display.max_columns\", 120)\n",
    "pd.set_option(\"display.width\", 140)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "VOgerwkl5Yg3",
   "metadata": {
    "id": "VOgerwkl5Yg3"
   },
   "source": [
    "### Load the ISLP College dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "rWmEObQX5Yg4",
   "metadata": {
    "id": "rWmEObQX5Yg4"
   },
   "outputs": [],
   "source": [
    "College = None\n",
    "err = None\n",
    "try:\n",
    "    from ISLP import load_data\n",
    "    College = load_data('College')\n",
    "except Exception as e:\n",
    "    err = e\n",
    "\n",
    "if College is None:\n",
    "    try:\n",
    "        from ISLP.datasets import load_data as load_data_alt\n",
    "        College = load_data_alt('College')\n",
    "    except Exception as e2:\n",
    "        err = (err, e2)\n",
    "\n",
    "if College is None:\n",
    "    raise RuntimeError(f\"Could not load College dataset. Error details: {err}\")\n",
    "\n",
    "df = College.copy()\n",
    "df.columns = df.columns.str.replace(r'[^0-9a-zA-Z]+', '_', regex=True)\n",
    "print(df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "F_OJLdih5Yg4",
   "metadata": {
    "id": "F_OJLdih5Yg4"
   },
   "source": [
    "## Part 1 — Exploratory data analysis\n",
    "\n",
    "We will be modeling **`Outstate`** (out-of-state tuition, continuous) as a function of a chosen predictor.  \n",
    "**Tasks**\n",
    "- Print a short summary of `Outstate`.\n",
    "- Show correlations between `Outstate` and several numeric predictors.\n",
    "- Make **scatterplots with LS lines** for 2–4 top predictors to visually assess near-linearity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "SbEESvzk5Yg4",
   "metadata": {
    "id": "SbEESvzk5Yg4"
   },
   "outputs": [],
   "source": [
    "target = 'Outstate'\n",
    "assert target in df.columns, f\"{target} not in columns; sample: {df.columns.tolist()[:12]}\"\n",
    "print(df[target].describe())\n",
    "\n",
    "# Candidate numeric predictors (no qualitative variables such as 'Private')\n",
    "candidates = [c for c in ['Top10perc','Room_Board','PhD','S_F_Ratio','Expend','Grad_Rate','perc_alumni','Terminal'] if c in df.columns]\n",
    "if not candidates:\n",
    "    candidates = [c for c in df.select_dtypes(include=[np.number]).columns if c != target][:8]\n",
    "\n",
    "print(\"Candidate numeric predictors:\", candidates)\n",
    "corrs = df[[target]+candidates].corr(numeric_only=True)[target].sort_values(ascending=False)\n",
    "print(\"Correlations with Outstate:\\n\", corrs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fArFOVwv5Yg4",
   "metadata": {
    "id": "fArFOVwv5Yg4"
   },
   "source": [
    "### Pick 2–4 predictors for EDA plots\n",
    "\n",
    "Set `top_nums` to a list of 2–4 column names from `candidates`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "HatXX5655Yg4",
   "metadata": {
    "id": "HatXX5655Yg4"
   },
   "outputs": [],
   "source": [
    "top_nums = # YOUR CODE HERE\n",
    "\n",
    "assert isinstance(top_nums, (list,tuple)) and 1 <= len(top_nums) <= 4, \"Choose 2–4 predictors\"\n",
    "for col in top_nums:\n",
    "    assert col in df.columns, f\"{col} must be in df\"\n",
    "print(\"Top predictors for EDA plots:\", top_nums)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "_wY2jxCn5Yg4",
   "metadata": {
    "id": "_wY2jxCn5Yg4"
   },
   "source": [
    "### Create the scatterplots + LS lines\n",
    "\n",
    "Loop over `top_nums`. One figure per predictor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sTJfkpfG5Yg4",
   "metadata": {
    "id": "sTJfkpfG5Yg4"
   },
   "outputs": [],
   "source": [
    "for x in top_nums:\n",
    "  # YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "-LAEChk95Yg5",
   "metadata": {
    "id": "-LAEChk95Yg5"
   },
   "source": [
    "## Part 2 — Fit the SLR (statsmodels OLS)\n",
    "\n",
    "Pick **one** numeric predictor `x1` for SLR (may be one of `top_nums`; e.g., `Top10perc`). Set `x1` and run the assert."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "mUsA_TGW5Yg5",
   "metadata": {
    "id": "mUsA_TGW5Yg5"
   },
   "outputs": [],
   "source": [
    "x1 = # YOUR CODE HERE\n",
    "assert isinstance(x1, str) and (x1 in df.columns), f\"x1 must be in df; consider: {candidates}\"\n",
    "print(\"x1 =\", x1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "JejZ9vRI5Yg5",
   "metadata": {
    "id": "JejZ9vRI5Yg5"
   },
   "source": [
    "### Fit with statsmodels.api.OLS (manual add_constant) and interpret\n",
    "\n",
    "1. Construct `X = sm.add_constant(x)` where `x = df[[x1]].values` and `y = df[target].values`.\n",
    "2. Fit: `model = sm.OLS(y, X).fit()` and print `model.summary()`.\n",
    "3. Compute **training RMSE** using **sklearn**: fit a `LinearRegression()` on the same `x` → predict; compute `rmse_slr = sqrt(MSE)`.\n",
    "4. Make plots:\n",
    "   - Scatter of `Outstate` vs `x1` with LS line\n",
    "   - Residuals vs fitted (from `model`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "Flp6G9iw5Yg5",
   "metadata": {
    "id": "Flp6G9iw5Yg5"
   },
   "outputs": [],
   "source": [
    "# 1) Design matrix\n",
    "x = # YOUR CODE HERE\n",
    "y = # YOUR CODE HERE\n",
    "X = # YOUR CODE HERE\n",
    "\n",
    "# 2) Fit statsmodels OLS\n",
    "model = # YOUR CODE HERE\n",
    "print(model.summary())\n",
    "\n",
    "# 3) RMSE via sklearn LinearRegression\n",
    "lr_slr = LinearRegression().fit(x, y)  # fit_intercept=True by default\n",
    "yhat = # YOUR CODE HERE\n",
    "from math import sqrt\n",
    "rmse_slr = sqrt(mean_squared_error(y, yhat))\n",
    "print(\"SLR RMSE (training):\", round(rmse_slr, 2))\n",
    "\n",
    "# 4) Plots\n",
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "YGOr4q8E5Yg5",
   "metadata": {
    "id": "YGOr4q8E5Yg5"
   },
   "source": [
    "## Part 3 — Fit the MLR with backward selection (statsmodels for p-values)\n",
    "\n",
    "- Split data 70/30.\n",
    "- Start with numeric predictors only (exclude qualitative variables).\n",
    "- Use **statsmodels OLS** (with `sm.add_constant`) to compute p-values for backward selection on the **training** set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1lTxru3Q5Yg5",
   "metadata": {
    "id": "1lTxru3Q5Yg5"
   },
   "outputs": [],
   "source": [
    "train_df, test_df = train_test_split(df, test_size=0.3, random_state=42)\n",
    "\n",
    "# Numeric candidate pool (exclude the target)\n",
    "numeric_pool = [c for c in ['Top10perc','Room_Board','PhD','S_F_Ratio','Expend','Grad_Rate','perc_alumni','Terminal'] if c in df.columns]\n",
    "numeric_pool = [c for c in numeric_pool if c != target]\n",
    "if not numeric_pool:\n",
    "    numeric_pool = [c for c in df.select_dtypes(include=[np.number]).columns if c != target][:8]\n",
    "\n",
    "print(\"Initial numeric candidate terms:\", numeric_pool)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5FUW1jtG5Yg5",
   "metadata": {
    "id": "5FUW1jtG5Yg5"
   },
   "source": [
    "### Implement backward selection by p-value\n",
    "\n",
    "Rules:\n",
    "- Fit OLS with `sm.OLS(y_train, sm.add_constant(X_train[kept]))`.\n",
    "- Use `model.pvalues` (drop `'const'`) to find the worst p-value.\n",
    "- Drop the worst term if p > 0.05; stop otherwise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3R9mVhbK5Yg5",
   "metadata": {
    "id": "3R9mVhbK5Yg5"
   },
   "outputs": [],
   "source": [
    "def fit_sm_ols(X_df, y_series):\n",
    "    X = sm.add_constant(X_df.values, has_constant='add')\n",
    "    return sm.OLS(y_series.values, X).fit()\n",
    "\n",
    "def backward_selection_by_p(train_df, response, terms, alpha_out=0.05):\n",
    "    kept = terms.copy()\n",
    "    while True:\n",
    "        X_train = train_df[kept]\n",
    "        y_train = train_df[response]\n",
    "        model = fit_sm_ols(X_train, y_train)\n",
    "        pvals = pd.Series(model.pvalues, index=['const']+kept).drop('const', errors='ignore')\n",
    "\n",
    "        worst_term = pvals.idxmax()\n",
    "        worst_p = pvals.max()\n",
    "\n",
    "        if worst_p > alpha_out and len(kept) > 1:\n",
    "            kept.remove(worst_term)\n",
    "        else:\n",
    "            break\n",
    "\n",
    "    final_model = fit_sm_ols(train_df[kept], train_df[response])\n",
    "    return kept, final_model\n",
    "\n",
    "kept_terms, mlr_model_train = backward_selection_by_p(train_df, target, numeric_pool, alpha_out=0.05)\n",
    "print(\"Selected terms:\", kept_terms)\n",
    "print(mlr_model_train.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ct3J7NJc5Yg5",
   "metadata": {
    "id": "ct3J7NJc5Yg5"
   },
   "source": [
    "## Part 4 — Predict with sklearn and report RMSE + visuals\n",
    "\n",
    "- Fit a `LinearRegression()` on the **training** set using **only** the selected `kept_terms` (no manual constant).\n",
    "- Compute **training RMSE** and **test RMSE**.\n",
    "- Plot **Predicted vs Actual** (test) with a 45° line.\n",
    "- Plot **Residuals vs Fitted** (test), using sklearn predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "Q0IPRq6p5Yg5",
   "metadata": {
    "id": "Q0IPRq6p5Yg5"
   },
   "outputs": [],
   "source": [
    "from math import sqrt\n",
    "Xtr = train_df[kept_terms].values\n",
    "ytr = train_df[target].values\n",
    "Xte = test_df[kept_terms].values\n",
    "yte = test_df[target].values\n",
    "lr_mlr = LinearRegression().fit(Xtr, ytr)\n",
    "yhat_tr = lr_mlr.predict(Xtr)\n",
    "yhat_te = lr_mlr.predict(Xte)\n",
    "rmse_train = sqrt(mean_squared_error(ytr, yhat_tr))\n",
    "rmse_test = sqrt(mean_squared_error(yte, yhat_te))\n",
    "print(\"MLR RMSE (train):\", round(rmse_train,2))\n",
    "print(\"MLR RMSE (test):\", round(rmse_test,2))\n",
    "\n",
    "plt.figure(); plt.scatter(yte, yhat_te, alpha=0.6)\n",
    "lims = [min(yte.min(), yhat_te.min()), max(yte.max(), yhat_te.max())]\n",
    "plt.plot(lims, lims); plt.xlabel(\"Actual\"); plt.ylabel(\"Predicted\"); plt.title(\"Predicted vs Actual (Test)\"); plt.show()\n",
    "\n",
    "resid_te = yte - yhat_te\n",
    "plt.figure(); plt.scatter(yhat_te, resid_te, alpha=0.6); plt.axhline(0, linewidth=1)\n",
    "plt.xlabel(\"Fitted (Test)\"); plt.ylabel(\"Residuals\"); plt.title(\"Residuals vs Fitted (Test)\"); plt.show()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "islp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
